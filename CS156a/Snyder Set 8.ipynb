{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "def formatOneToOne(points, digit1, digit2):\n",
    "    formattedInputs = []\n",
    "    formattedOutputs = []\n",
    "    \n",
    "    for point in points:\n",
    "        if point[0] == digit1:\n",
    "            formattedInputs.append([point[1], point[2]])\n",
    "            formattedOutputs.append(1)\n",
    "        elif point[0] == digit2:\n",
    "            formattedInputs.append([point[1], point[2]])\n",
    "            formattedOutputs.append(-1)\n",
    "    \n",
    "    return [formattedInputs, formattedOutputs]\n",
    "    \n",
    "    \n",
    "    \n",
    "def formatOneToMany(points, digit):\n",
    "    formattedInputs = []\n",
    "    formattedOutputs = []\n",
    "    \n",
    "    for point in points:\n",
    "        if point[0] == digit:\n",
    "            formattedInputs.append([point[1], point[2]])\n",
    "            formattedOutputs.append(1)\n",
    "        else:\n",
    "            formattedInputs.append([point[1], point[2]])\n",
    "            formattedOutputs.append(-1)\n",
    "    \n",
    "    return [formattedInputs, formattedOutputs]\n",
    "\n",
    "def formatOneToMany2(points, digit):\n",
    "    formatted = []\n",
    "    \n",
    "    for point in points:\n",
    "        if point[0] == digit:\n",
    "            formatted.append([point[1], point[2], 1])\n",
    "        else:\n",
    "            formatted.append([point[1], point[2], -1])\n",
    "    \n",
    "    return formatted;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doSoftMarginSVM(trainInputs, trainOutputs, testInputs, testOutputs, c, Q):\n",
    "    tool = svm.SVC(kernel='poly', C=c, degree=Q, gamma=1, coef0=1)\n",
    "    tool.fit(trainInputs, trainOutputs)\n",
    "    trainErrorCount = 0\n",
    "    testErrorCount = 0\n",
    "    for i in range(len(trainInputs)):\n",
    "        if tool.predict([trainInputs[i]]) != trainOutputs[i]:\n",
    "            trainErrorCount += 1\n",
    "    for i in range(len(testInputs)):\n",
    "        if tool.predict([testInputs[i]]) != testOutputs[i]:\n",
    "            testErrorCount += 1\n",
    "    return [trainErrorCount/len(trainInputs), testErrorCount/len(testInputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in for 0 versus all: 0.10588396653408312\n",
      "E_in for 2 versus all: 0.10026059525442327\n",
      "E_in for 4 versus all: 0.08942531888629818\n",
      "E_in for 6 versus all: 0.09107118365107666\n",
      "E_in for 8 versus all: 0.07433822520916199\n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 2\n",
    "\n",
    "#IMPORT DATA\n",
    "trainstrs = []\n",
    "teststrs = []\n",
    "trainlines = open('features.train.txt', 'r')\n",
    "testlines = open('features.test.txt', 'r')\n",
    "for line in trainlines:\n",
    "    trainstrs.append(line.split())\n",
    "for line in testlines:\n",
    "    teststrs.append(line.split())\n",
    "\n",
    "trainpts = []\n",
    "testpts = []\n",
    "for stri in trainstrs:\n",
    "    trainpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "for stri in teststrs:\n",
    "    testpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "    \n",
    "for digit in [0, 2, 4, 6, 8]:\n",
    "    #FORMAT DATA\n",
    "    temp = formatOneToMany(trainpts, digit)\n",
    "    trainInputs = temp[0]\n",
    "    trainOutputs = temp[1]\n",
    "    temp = formatOneToMany(testpts, digit)\n",
    "    testInputs = temp[0]\n",
    "    testOutputs = temp[1]\n",
    "    \n",
    "    #print(trainInputs)\n",
    "    #print(trainOutputs)\n",
    "    #print(testInputs)\n",
    "    #print(testOutputs)\n",
    "    \n",
    "    result = doSoftMarginSVM(trainInputs, trainOutputs, testInputs, testOutputs, 0.01, 2)\n",
    "    print('E_in for ' + str(digit) + ' versus all: ' + str(result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 0 versus all yields the highest E_in. Therefore the answer to question 2 is A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in for 1 versus all: 0.014401316691811822\n",
      "E_in for 3 versus all: 0.09024825126868742\n",
      "E_in for 5 versus all: 0.07625840076807022\n",
      "E_in for 7 versus all: 0.08846523110684405\n",
      "E_in for 9 versus all: 0.08832807570977919\n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 2\n",
    "\n",
    "#IMPORT DATA\n",
    "trainstrs = []\n",
    "teststrs = []\n",
    "trainlines = open('features.train.txt', 'r')\n",
    "testlines = open('features.test.txt', 'r')\n",
    "for line in trainlines:\n",
    "    trainstrs.append(line.split())\n",
    "for line in testlines:\n",
    "    teststrs.append(line.split())\n",
    "\n",
    "trainpts = []\n",
    "testpts = []\n",
    "for stri in trainstrs:\n",
    "    trainpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "for stri in teststrs:\n",
    "    testpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "    \n",
    "for digit in [1, 3, 5, 7, 9]:\n",
    "    #FORMAT DATA\n",
    "    temp = formatOneToMany(trainpts, digit)\n",
    "    trainInputs = temp[0]\n",
    "    trainOutputs = temp[1]\n",
    "    temp = formatOneToMany(testpts, digit)\n",
    "    testInputs = temp[0]\n",
    "    testOutputs = temp[1]\n",
    "    \n",
    "    result = doSoftMarginSVM(trainInputs, trainOutputs, testInputs, testOutputs, 0.01, 2)\n",
    "    print('E_in for ' + str(digit) + ' versus all: ' + str(result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that E_in is lowest for 1 versus all. Therefore the answer to question 3 is A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoftMarginSVMVectorNumber(trainInputs, trainOutputs, c, Q):\n",
    "    tool = svm.SVC(kernel='poly', C=c, degree=Q, gamma=1, coef0=1)\n",
    "    tool.fit(trainInputs, trainOutputs)\n",
    "    return len(tool.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors for 0 versus all: 2179\n",
      "Number of support vectors for 1 versus all: 386\n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 4\n",
    "\n",
    "#IMPORT DATA\n",
    "trainstrs = []\n",
    "teststrs = []\n",
    "trainlines = open('features.train.txt', 'r')\n",
    "testlines = open('features.test.txt', 'r')\n",
    "for line in trainlines:\n",
    "    trainstrs.append(line.split())\n",
    "for line in testlines:\n",
    "    teststrs.append(line.split())\n",
    "\n",
    "trainpts = []\n",
    "testpts = []\n",
    "for stri in trainstrs:\n",
    "    trainpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "for stri in teststrs:\n",
    "    testpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "    \n",
    "for digit in [0, 1]:\n",
    "    #FORMAT DATA\n",
    "    temp = formatOneToMany(trainpts, digit)\n",
    "    trainInputs = temp[0]\n",
    "    trainOutputs = temp[1]\n",
    "    \n",
    "    result = getSoftMarginSVMVectorNumber(trainInputs, trainOutputs, 0.01, 2)\n",
    "    print('Number of support vectors for ' + str(digit) + ' versus all: ' + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the difference is 2179 - 386 = 1793 which is closest to 1800, so the answer to question 4 is C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001:\n",
      "E_in: 0.004484304932735426\n",
      "E_out: 0.01650943396226415\n",
      "Number of support vectors: 76\n",
      " \n",
      "C = 0.01:\n",
      "E_in: 0.004484304932735426\n",
      "E_out: 0.018867924528301886\n",
      "Number of support vectors: 34\n",
      " \n",
      "C = 0.1:\n",
      "E_in: 0.004484304932735426\n",
      "E_out: 0.018867924528301886\n",
      "Number of support vectors: 24\n",
      " \n",
      "C = 1:\n",
      "E_in: 0.0032030749519538757\n",
      "E_out: 0.018867924528301886\n",
      "Number of support vectors: 24\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 5\n",
    "\n",
    "#IMPORT DATA\n",
    "trainstrs = []\n",
    "teststrs = []\n",
    "trainlines = open('features.train.txt', 'r')\n",
    "testlines = open('features.test.txt', 'r')\n",
    "for line in trainlines:\n",
    "    trainstrs.append(line.split())\n",
    "for line in testlines:\n",
    "    teststrs.append(line.split())\n",
    "\n",
    "trainpts = []\n",
    "testpts = []\n",
    "for stri in trainstrs:\n",
    "    trainpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "for stri in teststrs:\n",
    "    testpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "    \n",
    "#FORMAT DATA\n",
    "temp = formatOneToOne(trainpts, 1, 5)\n",
    "trainInputs = temp[0]\n",
    "trainOutputs = temp[1]\n",
    "temp = formatOneToOne(testpts, 1, 5)\n",
    "testInputs = temp[0]\n",
    "testOutputs = temp[1]\n",
    "\n",
    "for C in [0.001, 0.01, 0.1, 1]:\n",
    "    print('C = ' + str(C) + ':')\n",
    "    result = doSoftMarginSVM(trainInputs, trainOutputs, testInputs, testOutputs, C, 2)\n",
    "    print('E_in: ' + str(result[0]))\n",
    "    print('E_out: ' + str(result[1]))\n",
    "    print('Number of support vectors: ' + str(getSoftMarginSVMVectorNumber(trainInputs, trainOutputs, C, 2)))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that maximum C produces minimum E_in, so the answer to question 5 is D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q = 2\n",
      "C = 0.0001:\n",
      "E_in: 0.008968609865470852\n",
      "E_out: 0.01650943396226415\n",
      "Number of support vectors: 236\n",
      " \n",
      "C = 0.001:\n",
      "E_in: 0.004484304932735426\n",
      "E_out: 0.01650943396226415\n",
      "Number of support vectors: 76\n",
      " \n",
      "C = 0.01:\n",
      "E_in: 0.004484304932735426\n",
      "E_out: 0.018867924528301886\n",
      "Number of support vectors: 34\n",
      " \n",
      "C = 1:\n",
      "E_in: 0.0032030749519538757\n",
      "E_out: 0.018867924528301886\n",
      "Number of support vectors: 24\n",
      " \n",
      " \n",
      "Q = 5\n",
      "C = 0.0001:\n",
      "E_in: 0.004484304932735426\n",
      "E_out: 0.018867924528301886\n",
      "Number of support vectors: 26\n",
      " \n",
      "C = 0.001:\n",
      "E_in: 0.004484304932735426\n",
      "E_out: 0.02122641509433962\n",
      "Number of support vectors: 25\n",
      " \n",
      "C = 0.01:\n",
      "E_in: 0.003843689942344651\n",
      "E_out: 0.02122641509433962\n",
      "Number of support vectors: 23\n",
      " \n",
      "C = 1:\n",
      "E_in: 0.0032030749519538757\n",
      "E_out: 0.02122641509433962\n",
      "Number of support vectors: 21\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 6\n",
    "\n",
    "#IMPORT DATA\n",
    "trainstrs = []\n",
    "teststrs = []\n",
    "trainlines = open('features.train.txt', 'r')\n",
    "testlines = open('features.test.txt', 'r')\n",
    "for line in trainlines:\n",
    "    trainstrs.append(line.split())\n",
    "for line in testlines:\n",
    "    teststrs.append(line.split())\n",
    "\n",
    "trainpts = []\n",
    "testpts = []\n",
    "for stri in trainstrs:\n",
    "    trainpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "for stri in teststrs:\n",
    "    testpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "    \n",
    "#FORMAT DATA\n",
    "temp = formatOneToOne(trainpts, 1, 5)\n",
    "trainInputs = temp[0]\n",
    "trainOutputs = temp[1]\n",
    "temp = formatOneToOne(testpts, 1, 5)\n",
    "testInputs = temp[0]\n",
    "testOutputs = temp[1]\n",
    "\n",
    "for Q in [2, 5]:\n",
    "    print('Q = ' + str(Q))\n",
    "    for C in [0.0001, 0.001, 0.01, 1]:\n",
    "        print('C = ' + str(C) + ':')\n",
    "        result = doSoftMarginSVM(trainInputs, trainOutputs, testInputs, testOutputs, C, Q)\n",
    "        print('E_in: ' + str(result[0]))\n",
    "        print('E_out: ' + str(result[1]))\n",
    "        print('Number of support vectors: ' + str(getSoftMarginSVMVectorNumber(trainInputs, trainOutputs, C, Q)))\n",
    "        print(' ')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the number of support vectors is lower at C = 0.001 when Q = 5. Therefore the answer to problem 6 is B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 38, 15, 11, 9]\n",
      "[0.009299363057324843, 0.004649681528662418, 0.005605095541401275, 0.005159235668789808, 0.004777070063694267]\n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 7 & 8\n",
    "\n",
    "#IMPORT DATA\n",
    "trainstrs = []\n",
    "teststrs = []\n",
    "trainlines = open('features.train.txt', 'r')\n",
    "testlines = open('features.test.txt', 'r')\n",
    "for line in trainlines:\n",
    "    trainstrs.append(line.split())\n",
    "for line in testlines:\n",
    "    teststrs.append(line.split())\n",
    "\n",
    "trainpts = []\n",
    "testpts = []\n",
    "for stri in trainstrs:\n",
    "    trainpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "for stri in teststrs:\n",
    "    testpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "    \n",
    "#FORMAT DATA\n",
    "temp = formatOneToOne(trainpts, 1, 5)\n",
    "trainInputs = temp[0]\n",
    "trainOutputs = temp[1]\n",
    "temp = formatOneToOne(testpts, 1, 5)\n",
    "testInputs = temp[0]\n",
    "testOutputs = temp[1]\n",
    "\n",
    "counts = [0, 0, 0, 0, 0]\n",
    "avg_errors = [0,0,0,0,0]\n",
    "iteration = 1\n",
    "for repeat in range(100):\n",
    "    iteration += 1\n",
    "    errors = []\n",
    "    for C in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
    "        totalError = 0\n",
    "        a = list(range(len(trainInputs)))\n",
    "        random.shuffle(a)\n",
    "        for i in range(10):\n",
    "            tempInputs = []\n",
    "            tempOutputs = []\n",
    "            validateInputs = []\n",
    "            validateOutputs = []\n",
    "            for k in range(len(a)):\n",
    "                if k < (len(a))/10:\n",
    "                    validateInputs.append(trainInputs[a[k]])\n",
    "                    validateOutputs.append(trainOutputs[a[k]])\n",
    "                else:\n",
    "                    tempInputs.append(trainInputs[a[k]])\n",
    "                    tempOutputs.append(trainOutputs[a[k]])\n",
    "            result = doSoftMarginSVM(tempInputs, tempOutputs, validateInputs, validateOutputs, C, 2)\n",
    "            totalError += result[1]/10.0\n",
    "        errors.append(totalError)\n",
    "        \n",
    "    for i in range(5):\n",
    "        avg_errors[i] += errors[i]/100.0\n",
    "        \n",
    "    if errors[0] <= errors[1] and errors[0] <= errors[2] and errors[0] <= errors[3] and errors[0] <= errors[4]:\n",
    "        counts[0] += 1\n",
    "    elif errors[1] <= errors[2] and errors[1] <= errors[3] and errors[1] <= errors[4]:\n",
    "        counts[1] += 1\n",
    "    elif errors[2] <= errors[3] and errors[2] <= errors[4]:\n",
    "        counts[2] += 1\n",
    "    elif errors[3] <= errors[4]:\n",
    "        counts[3] += 1\n",
    "    else:\n",
    "        counts[4] += 1\n",
    "\n",
    "print(counts)\n",
    "print(avg_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most chosen C is the second one, which corresponds to C=0.001. Therefore the answer to question 7 is B.\n",
    "We can see that the average error corresponding to C=0.001 is closest to 0.005, so the answer to question 8 is C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01\n",
      "E_in for 1 versus 5: 0.003843689942344651\n",
      "E_out for 1 versus 5: 0.02358490566037736\n",
      " \n",
      "C = 1\n",
      "E_in for 1 versus 5: 0.004484304932735426\n",
      "E_out for 1 versus 5: 0.02122641509433962\n",
      " \n",
      "C = 100\n",
      "E_in for 1 versus 5: 0.0032030749519538757\n",
      "E_out for 1 versus 5: 0.018867924528301886\n",
      " \n",
      "C = 10000\n",
      "E_in for 1 versus 5: 0.0025624599615631004\n",
      "E_out for 1 versus 5: 0.02358490566037736\n",
      " \n",
      "C = 1000000\n",
      "E_in for 1 versus 5: 0.0006406149903907751\n",
      "E_out for 1 versus 5: 0.02358490566037736\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 9 & 10\n",
    "\n",
    "def doSoftMarginSVM2(trainInputs, trainOutputs, testInputs, testOutputs, c):\n",
    "    tool = svm.SVC(kernel='rbf', gamma=1, C=c)\n",
    "    tool.fit(trainInputs, trainOutputs)\n",
    "    trainErrorCount = 0\n",
    "    testErrorCount = 0\n",
    "    for i in range(len(trainInputs)):\n",
    "        if tool.predict([trainInputs[i]]) != trainOutputs[i]:\n",
    "            trainErrorCount += 1\n",
    "    for i in range(len(testInputs)):\n",
    "        if tool.predict([testInputs[i]]) != testOutputs[i]:\n",
    "            testErrorCount += 1\n",
    "    return [trainErrorCount/len(trainInputs), testErrorCount/len(testInputs)]\n",
    "\n",
    "#IMPORT DATA\n",
    "trainstrs = []\n",
    "teststrs = []\n",
    "trainlines = open('features.train.txt', 'r')\n",
    "testlines = open('features.test.txt', 'r')\n",
    "for line in trainlines:\n",
    "    trainstrs.append(line.split())\n",
    "for line in testlines:\n",
    "    teststrs.append(line.split())\n",
    "\n",
    "trainpts = []\n",
    "testpts = []\n",
    "for stri in trainstrs:\n",
    "    trainpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "for stri in teststrs:\n",
    "    testpts.append([float(stri[0]), float(stri[1]), float(stri[2])])\n",
    "    \n",
    "\n",
    "temp = formatOneToOne(trainpts, 1, 5)\n",
    "trainInputs = temp[0]\n",
    "trainOutputs = temp[1]\n",
    "temp = formatOneToOne(testpts, 1, 5)\n",
    "testInputs = temp[0]\n",
    "testOutputs = temp[1]\n",
    "\n",
    "#print(trainInputs)\n",
    "#print(trainOutputs)\n",
    "#print(testInputs)\n",
    "#print(testOutputs)\n",
    "\n",
    "for C in [0.01, 1, 100, 10000, 1000000]:\n",
    "    result = doSoftMarginSVM2(trainInputs, trainOutputs, testInputs, testOutputs, C)\n",
    "    print('C = ' + str(C))\n",
    "    print('E_in for 1 versus 5: ' + str(result[0]))\n",
    "    print('E_out for 1 versus 5: ' + str(result[1]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the lowest E_in occurs at C=1000000, so the answer to question 9 is E.\n",
    "We can see that the lowest E_out occurs at C=100, so the answer to question 10 is C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
